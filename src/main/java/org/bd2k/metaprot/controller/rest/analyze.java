package org.bd2k.metaprot.controller.rest;

import org.bd2k.metaprot.scheduler.TaskScheduler;
import org.bd2k.metaprot.aws.S3Client;
import org.bd2k.metaprot.aws.S3Status;
import org.bd2k.metaprot.dbaccess.DAOImpl;
import org.bd2k.metaprot.exception.BadRequestException;
import org.bd2k.metaprot.exception.ServerException;
import org.bd2k.metaprot.model.*;
import org.bd2k.metaprot.util.FileAccess;
import org.bd2k.metaprot.util.Globals;
import org.bd2k.metaprot.util.RManager;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.DependsOn;
import org.springframework.web.bind.annotation.*;

import java.io.File;
import java.util.ArrayList;
import java.util.Date;
import java.util.List;
import java.util.UUID;

/**
 * REST controller that exposes endpoints
 * related to analyzing files.
 *
 * Created by allengong on 8/12/16.
 */
@RestController
@RequestMapping("/analyze")
@DependsOn({"Globals"})
public class analyze {

    @Autowired
    private S3Client copakbS3;

    @Autowired
    private DAOImpl dao;

    // for path construction
    private String root = Globals.getPathRoot();
    private String sep = Globals.getPathSeparator();
    private String rScriptLoc = Globals.getrScriptLocation();

    // "/ssd2/metaprot"
    private final String LOCAL_FILE_DOWNLOAD_PATH = root + "ssd2" + sep + "metaprot";

    // "src/main/resources/R/scripts/r_sample_code.R"
    private final String METABOLITES_R_SCRIPT_LOC = rScriptLoc + "r_sample_code.R";
    private final String TEMPORAL_PATTERNS_R_SCRIPT_LOC = rScriptLoc + "scatter_plot_cluster.R";

    // handle to perform R related logic
    private RManager manager = null;

    /**
     * Analyzes an uploaded CSV file for metabolite analysis.
     *
     * Maps to:
     *
     * HTTP POST /analyze/metabolites/{token}
     *
     * @param token uuid generated by HTTP GET /analyze/token
     * @param key AWS S3 key pointing to the uploaded file
     * @param pThreshold p value threshold
     * @param fcThreshold fold change threshold
     *
     * @return an HTML formatted message ready to be displayed to the end user.
     */
    @RequestMapping(value = "/metabolites/{token}", method = RequestMethod.POST)
    public String analyzeMetabolites(@PathVariable("token") String token,
                                     @RequestParam("objectKey") String key,
                                     @RequestParam("pThreshold") double pThreshold,
                                     @RequestParam("fcThreshold") double fcThreshold) {

        // validation
        String[] keyArr = key.split("/");
        if (!(key.startsWith("user-input/" + token)) ||
                pThreshold < 0 ||
                fcThreshold < 0 ||
                !(keyArr[keyArr.length-2].equals(token)) ||
                keyArr.length != 3) {

            // should return error message
            throw new BadRequestException("Invalid request, please try again later.");
        }

        S3Status s3Status = copakbS3.pullAndStoreObject(key, LOCAL_FILE_DOWNLOAD_PATH + sep + token);
        int status = s3Status.getStatusCode();
        System.out.println("new status s3: " + s3Status.toString());

        // error
        if (status == -1) {
            throw new ServerException("There was an error with your request, please try again later.");
        } else if (status > 0) {
            throw new BadRequestException(copakbS3.getAWSStatusMessage(status));
        }

        // everything is OK on the server end, attempt to analyze the file
        File rScript;
        try {
            // generate TaskInfo and queue task for scheduler
            TaskInfo taskInfo = new TaskInfo(token, keyArr[keyArr.length-1], s3Status.getFileSize());
            TaskScheduler scheduler = TaskScheduler.getInstance();
            int portUsed = scheduler.scheduleTask(taskInfo);
            System.out.println("Port used for Rserve: " + portUsed);

            // run the R commands
            manager = RManager.getInstance(portUsed);
            rScript = new File(METABOLITES_R_SCRIPT_LOC);
            String str = rScript.getAbsolutePath().replace("\\","\\\\");        // affects window env only

            manager.runRScript(str);        // (re) initializes R environment
            manager.runRCommand("analyze.file('" + LOCAL_FILE_DOWNLOAD_PATH + sep + token
                    + sep + keyArr[keyArr.length-1] + "', '" + LOCAL_FILE_DOWNLOAD_PATH + sep +
                    token + sep + "data.csv', '" + LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep + "volcano.png', " +
                    pThreshold + ", " + fcThreshold + ")");

            // tell scheduler that all R commands have completed
            scheduler.endTask(portUsed);
            manager.closeConnection();
        } catch (Exception e) {
            // handle exception so that we can return appropriate error messages
            e.printStackTrace();
            throw new ServerException("There was an error with our R Engine. Please try again at a later time.");
        }

        // store results to database, TODO any new logic to read in all result files, for now just one, maybe just need to modify the file access function to return a list of lists
        List<List<MetaboliteStat>> totalResults = new ArrayList<>();
        List<MetaboliteStat> results = new FileAccess().getMetaboliteAnalysisResults(token);
        totalResults.add(results);

        Task currentTask = new Task(token, new Date(), keyArr[keyArr.length-1], pThreshold, fcThreshold, totalResults);
        boolean taskSaved = dao.saveTask(currentTask);

        if (!taskSaved) {
            throw new BadRequestException("There was an issue with your task token. Please try again at a later time.");
        }

        // analysis complete and results recorded, safe to delete all temporary files
        new FileAccess().deleteTemporaryAnalysisFiles(token);

        // everything went well, success message
        String successMessage = "Your file has been successfully analyzed! Head over to the %s page" +
                " to see the report.";

        return String.format(successMessage, "<a href='/metabolite-analysis/results/" + token + "'>results</a>");

    }

    /**
     * Analyzes an uploaded CSV file for pattern recognition analysis.
     *
     * Maps to:
     *
     * HTTP POST /analyze/pattern/{token}
     *
     * @param token uuid generated by HTTP GET /analyze/token
     * @param key AWS S3 key pointing to the uploaded file
     *
     * @return an HTML formatted message ready to be displayed to the end user.
     */
    @RequestMapping(value = "/pattern/{token}", method = RequestMethod.POST)
    public String analyzePatterns(@PathVariable("token") String token,
                                  @RequestParam("objectKey") String key,
                                  @RequestParam("numClusters") int numClusters) {

        // validation
        String[] keyArr = key.split("/");
        if (!(key.startsWith("user-input/" + token)) ||
                !(keyArr[keyArr.length-2].equals(token)) ||
                keyArr.length != 3 ||
                numClusters < 1) {

            // should return error message
            throw new BadRequestException("Invalid request, please try again later.");
        }

        // grab uploaded file from S3
        S3Status s3Status = copakbS3.pullAndStoreObject(key, LOCAL_FILE_DOWNLOAD_PATH + sep + token);
        int status = s3Status.getStatusCode();
        System.out.println("new status s3: " + s3Status.toString());

        // check for errors in s3 pull/store
        if (status == -1) {
            throw new ServerException("There was an error with your request, please try again later.");
        } else if (status > 0) {
            throw new BadRequestException(copakbS3.getAWSStatusMessage(status));
        }

        // try to analyze the file with R
        File rScript;
        try {
            TaskInfo taskInfo = new TaskInfo(token, keyArr[keyArr.length-1], s3Status.getFileSize());
            TaskScheduler scheduler = TaskScheduler.getInstance();
            int portToUse = scheduler.scheduleTask(taskInfo);
            System.out.println("Port to use for Rserve: " + portToUse);

            // get manager instance and run R commands
            RManager manager = RManager.getInstance(portToUse);
            rScript = new File(TEMPORAL_PATTERNS_R_SCRIPT_LOC);
            String absScriptPath = rScript.getAbsolutePath().replace("\\","\\\\");        // affects window env only

            manager.runRScript(absScriptPath);          // source the R script
            manager.runRCommand("analyze.temporal.patterns('" + LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep +
            keyArr[keyArr.length - 1] + "', '" + LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep + "clustered_result.csv', " +
                    numClusters + ")");

            scheduler.endTask(portToUse);   // notify scheduler that task is complete (all R commands done)
            manager.closeConnection();
        } catch (Exception e) {
            e.printStackTrace();
            throw new ServerException("There was an error with our R Engine. Please try again at a later time.");
        }


        List<List<PatternRecogStat>> results = new FileAccess().getPatternRecogResults(token);
        PatternRecogTask task = new PatternRecogTask(token, new Date(), keyArr[keyArr.length-1], s3Status.getFileSize(),
                numClusters, results);

        boolean taskSaved = dao.saveTask(task);

        if (!taskSaved) {
            throw new BadRequestException("There was an issue with your task token. Please try again at a later time.");
        }

        // analysis complete and results recorded, safe to delete all temporary files
        //new FileAccess().deleteTemporaryAnalysisFiles(token);

        // everything went well, success message
        String successMessage = "Your file has been successfully analyzed! Head over to the %s page" +
                " to see the report.";

        return String.format(successMessage, "<a href='/temporal-pattern-recognition/results/" + token + "'>results</a>");

    }

    /**
     * Performs analyzes on a previously uploaded CSV file for pattern recog analysis.
     * If the file/directory no longer exists locally (i.e. expired), then an error is thrown.
     * Instead of returning an HTML response, the results of the analysis are returned in JSON.
     *
     * Maps to:
     *
     * HTTP GET /analyze/pattern/re-analyze/{token}?numClusters={int}
     *
     * @param token uuid generated by HTTP GET /analyze/token
     *
     * @return a list
     */
    @RequestMapping(value="/pattern/re-analyze/{token}", method = RequestMethod.GET)
    public List<List<PatternRecogStat>> reanalyzePatternRecognition(@PathVariable(value="token") String token,
                                                                    @RequestParam("numClusters") int numClusters) {

        // validation
        PatternRecogTask task = dao.getPatternRecogTask(token);
        File targetDir = new File(LOCAL_FILE_DOWNLOAD_PATH + sep + token);
        File targetFile = new File(LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep + task.getFileName());
        if (!targetDir.exists() || !targetFile.exists() || task==null || numClusters < 1) {
            throw new BadRequestException("Bad request");
        }

        // target file, directory, and db record exist, proceed with reanalyzing the file
        TaskInfo taskInfo = new TaskInfo(token, task.getFileName(), task.getFileSize());
        TaskScheduler scheduler = TaskScheduler.getInstance();
        int portToUse = scheduler.scheduleTask(taskInfo);

        try {
            // analyze the file again
            manager =  RManager.getInstance(portToUse);

            File rScript = new File(TEMPORAL_PATTERNS_R_SCRIPT_LOC);
            String absScriptPath = rScript.getAbsolutePath().replace("\\","\\\\");        // affects window env only

            manager.runRScript(absScriptPath);          // source the R script
            manager.runRCommand("analyze.temporal.patterns('" + LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep +
                    task.getFileName() + "', '" + LOCAL_FILE_DOWNLOAD_PATH + sep + token + sep + "clustered_result.csv', "
                    + numClusters +  ")");

            // notify scheduler that all R commands complete
            scheduler.endTask(portToUse);
            manager.closeConnection();
        } catch (Exception e) {
            e.printStackTrace();
            throw new ServerException("There was an issue with our R Engine. Please try again later.");
        }

        // update mongo and return results to user
        List<List<PatternRecogStat>> results = new FileAccess().getPatternRecogResults(token);
        task.setTimeStamp(new Date());
        task.setResults(results);
        task.setNumClusters(numClusters);

        dao.saveOrUpdateTask(task); // always succeeds

        return results;
    }

    @RequestMapping(value = "/token", method = RequestMethod.GET)
    public String getToken() {
        return UUID.randomUUID().toString();
    }
}
